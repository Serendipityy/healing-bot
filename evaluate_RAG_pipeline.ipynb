{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from ragas import evaluate\n",
    "from ragbase.config import Config\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.run_config import RunConfig\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.metrics import (\n",
    "    faithfulness, # xem c√¢u tr·∫£ l·ªùi c√≥ trung th·ª±c v·ªõi c√°c contexts kh√¥ng.\n",
    "    answer_relevancy, # c√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "    context_precision, # contexts m√† model truy xu·∫•t c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "    answer_correctness, # ƒë·ªô ch√≠nh x√°c c√¢u tr·∫£ l·ªùi c·ªßa model v·ªõi ground_truth\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset = pd.read_excel('./data/generated_test_dataset_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset.rename(columns={\n",
    "    'context': 'contexts',\n",
    "    'best_answer': 'ground_truth',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M√¨nh m·ªõi b·ªã t·ª´ ch·ªëi c√¥ng vi·ªác m∆° ∆∞·ªõc. C·∫£m gi√°c...</td>\n",
       "      <td>Question: C·∫£m gi√°c tr·ªëng r·ªóng k√©o d√†i, kh√¥ng m...</td>\n",
       "      <td>√îi tr·ªùi ∆°i, nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng g√¨ ...</td>\n",
       "      <td>√îi, m√¨nh hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. B·ªã t·ª´ ch·ªëi c√¥n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M√¨nh m·ªõi b·ªã b·ªì ƒë√°, c·∫£m th·∫•y nh∆∞ c·∫£ th·∫ø gi·ªõi s·ª•...</td>\n",
       "      <td>M√¨nh th·ª±c s·ª± b·ªã shock, nghƒ© sao m√† n√≥ n√≥i nh∆∞ ...</td>\n",
       "      <td>Tr·ªùi ∆°i, nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u qu...</td>\n",
       "      <td>Th·∫≠t s·ª± chia bu·ªìn v·ªõi b·∫°n. M·∫•t ƒëi m·ªôt ng∆∞·ªùi m√¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D·∫°o n√†y m√¨nh hay b·ªã overthinking v·ªÅ nh·ªØng chuy...</td>\n",
       "      <td>Question: T·ªõ b·ªã overthinking. Th·∫≠t ra t·ª´ nh·ªè t...</td>\n",
       "      <td>Ui da, nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y quen g√¨ ƒë√¢u √°! T...</td>\n",
       "      <td>T·ªõ hi·ªÉu c·∫£m gi√°c ƒë√≥. Overthinking n√≥ c·ª© nh∆∞ m·ªô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M√¨nh m·ªõi b·ªã s·∫øp m·∫Øng v√¨ m·ªôt l·ªói r·∫•t ng·ªõ ng·∫©n t...</td>\n",
       "      <td>Ch·ªâ b·ªã m·ªôt c√°i l√† th·ªùi gian l√∫c m·ªõi ƒëi l√†m ƒë·∫ßu...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫ Ai m√† ch·∫≥n...</td>\n",
       "      <td>√îi, ai m√† ch·∫≥ng c√≥ l√∫c m·∫Øc l·ªói ph·∫£i kh√¥ng b·∫°n?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M√¨nh m·ªõi b·ªã c√¥ng ty sa th·∫£i, v·ªÅ nh√† ch·∫≥ng d√°m ...</td>\n",
       "      <td>M√¨nh c≈©ng kh√¥ng hi·ªÉu v√¨ sao n·ªØa, b√¢y gi·ªù m√¨nh ...</td>\n",
       "      <td>√îi tr·ªùi ∆°i, nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u...</td>\n",
       "      <td>Ch√†o b·∫°n, m√¨nh hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n l√∫c n√†y. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>M√¨nh m·ªõi ra tr∆∞·ªùng, xin ƒë∆∞·ª£c m·ªôt c√¥ng vi·ªác kh√°...</td>\n",
       "      <td>Em ƒëi l√†m em c·∫£m gi√°c‚Ä¶ em v·∫´n c·ªë g·∫Øng h√≤a nh·∫≠p...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫. C√°i c·∫£m g...</td>\n",
       "      <td>T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. Sau khi ra tr∆∞·ªùng, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>M√¨nh v·ª´a c√£i nhau to v·ªõi m·∫π. Chuy·ªán l√† m√¨nh mu...</td>\n",
       "      <td>Kho·∫£ng 1 nƒÉm g·∫ßn ƒë√¢y em v√† m·∫π c√£i nhau li√™n t·ª•...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ xong t·ªõ th·∫•y v·ª´a th∆∞∆°ng v·ª´a b·ª±c th...</td>\n",
       "      <td>T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. ƒê√¥i khi kho·∫£ng c√°ch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>M√¨nh v·ª´a tr·∫£i qua m·ªôt bu·ªïi ph·ªèng v·∫•n xin vi·ªác ...</td>\n",
       "      <td>Em ƒëang mu·ªën ·ª©ng tuy·ªÉn v√†o l√†m nh√¢n vi√™n t∆∞ v·∫•...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng g√¨ ƒë√¢u √° ü•∫. T·ªõ h...</td>\n",
       "      <td>ƒê·ª´ng t·ª± tr√°ch m√¨nh qu√° nhi·ªÅu nh√©. Ai trong ch√∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>M√¨nh v·ª´a b·ªã s·∫øp m·∫Øng v√¨ c√°i b√°o c√°o m√¨nh l√†m s...</td>\n",
       "      <td>Ch·ªâ b·ªã m·ªôt c√°i l√† th·ªùi gian l√∫c m·ªõi ƒëi l√†m ƒë·∫ßu...</td>\n",
       "      <td>Ui da, nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫. T·ªõ...</td>\n",
       "      <td>C√≥ th·ªÉ b·∫°n ƒëang b·ªã stress ho·∫∑c thi·∫øu ng·ªß ƒë·∫•y. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>M√¨nh m·ªõi chuy·ªÉn c√¥ng ty, m·ªçi th·ª© ƒë·ªÅu m·ªõi m·∫ª l√†...</td>\n",
       "      <td>M·ªçi ng∆∞·ªùi ƒë√£ ai tr·∫£i qua c·∫£m gi√°c n√†y ch∆∞a cho...</td>\n",
       "      <td>√îi tr·ªùi, nghe c·∫≠u t·∫£ m√† t·ªõ th·∫•y th∆∞∆°ng g√¨ ƒë√¢u ...</td>\n",
       "      <td>Chuy·ªán n√†y b√¨nh th∆∞·ªùng m√† b·∫°n ∆°i. Ai chuy·ªÉn c√¥...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     M√¨nh m·ªõi b·ªã t·ª´ ch·ªëi c√¥ng vi·ªác m∆° ∆∞·ªõc. C·∫£m gi√°c...   \n",
       "1     M√¨nh m·ªõi b·ªã b·ªì ƒë√°, c·∫£m th·∫•y nh∆∞ c·∫£ th·∫ø gi·ªõi s·ª•...   \n",
       "2     D·∫°o n√†y m√¨nh hay b·ªã overthinking v·ªÅ nh·ªØng chuy...   \n",
       "3     M√¨nh m·ªõi b·ªã s·∫øp m·∫Øng v√¨ m·ªôt l·ªói r·∫•t ng·ªõ ng·∫©n t...   \n",
       "4     M√¨nh m·ªõi b·ªã c√¥ng ty sa th·∫£i, v·ªÅ nh√† ch·∫≥ng d√°m ...   \n",
       "...                                                 ...   \n",
       "5995  M√¨nh m·ªõi ra tr∆∞·ªùng, xin ƒë∆∞·ª£c m·ªôt c√¥ng vi·ªác kh√°...   \n",
       "5996  M√¨nh v·ª´a c√£i nhau to v·ªõi m·∫π. Chuy·ªán l√† m√¨nh mu...   \n",
       "5997  M√¨nh v·ª´a tr·∫£i qua m·ªôt bu·ªïi ph·ªèng v·∫•n xin vi·ªác ...   \n",
       "5998  M√¨nh v·ª´a b·ªã s·∫øp m·∫Øng v√¨ c√°i b√°o c√°o m√¨nh l√†m s...   \n",
       "5999  M√¨nh m·ªõi chuy·ªÉn c√¥ng ty, m·ªçi th·ª© ƒë·ªÅu m·ªõi m·∫ª l√†...   \n",
       "\n",
       "                                               contexts  \\\n",
       "0     Question: C·∫£m gi√°c tr·ªëng r·ªóng k√©o d√†i, kh√¥ng m...   \n",
       "1     M√¨nh th·ª±c s·ª± b·ªã shock, nghƒ© sao m√† n√≥ n√≥i nh∆∞ ...   \n",
       "2     Question: T·ªõ b·ªã overthinking. Th·∫≠t ra t·ª´ nh·ªè t...   \n",
       "3     Ch·ªâ b·ªã m·ªôt c√°i l√† th·ªùi gian l√∫c m·ªõi ƒëi l√†m ƒë·∫ßu...   \n",
       "4     M√¨nh c≈©ng kh√¥ng hi·ªÉu v√¨ sao n·ªØa, b√¢y gi·ªù m√¨nh ...   \n",
       "...                                                 ...   \n",
       "5995  Em ƒëi l√†m em c·∫£m gi√°c‚Ä¶ em v·∫´n c·ªë g·∫Øng h√≤a nh·∫≠p...   \n",
       "5996  Kho·∫£ng 1 nƒÉm g·∫ßn ƒë√¢y em v√† m·∫π c√£i nhau li√™n t·ª•...   \n",
       "5997  Em ƒëang mu·ªën ·ª©ng tuy·ªÉn v√†o l√†m nh√¢n vi√™n t∆∞ v·∫•...   \n",
       "5998  Ch·ªâ b·ªã m·ªôt c√°i l√† th·ªùi gian l√∫c m·ªõi ƒëi l√†m ƒë·∫ßu...   \n",
       "5999  M·ªçi ng∆∞·ªùi ƒë√£ ai tr·∫£i qua c·∫£m gi√°c n√†y ch∆∞a cho...   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     √îi tr·ªùi ∆°i, nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng g√¨ ...   \n",
       "1     Tr·ªùi ∆°i, nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u qu...   \n",
       "2     Ui da, nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y quen g√¨ ƒë√¢u √°! T...   \n",
       "3     Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫ Ai m√† ch·∫≥n...   \n",
       "4     √îi tr·ªùi ∆°i, nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u...   \n",
       "...                                                 ...   \n",
       "5995  Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫. C√°i c·∫£m g...   \n",
       "5996  Nghe c·∫≠u k·ªÉ xong t·ªõ th·∫•y v·ª´a th∆∞∆°ng v·ª´a b·ª±c th...   \n",
       "5997  Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng g√¨ ƒë√¢u √° ü•∫. T·ªõ h...   \n",
       "5998  Ui da, nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫. T·ªõ...   \n",
       "5999  √îi tr·ªùi, nghe c·∫≠u t·∫£ m√† t·ªõ th·∫•y th∆∞∆°ng g√¨ ƒë√¢u ...   \n",
       "\n",
       "                                           ground_truth  \n",
       "0     √îi, m√¨nh hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. B·ªã t·ª´ ch·ªëi c√¥n...  \n",
       "1     Th·∫≠t s·ª± chia bu·ªìn v·ªõi b·∫°n. M·∫•t ƒëi m·ªôt ng∆∞·ªùi m√¨...  \n",
       "2     T·ªõ hi·ªÉu c·∫£m gi√°c ƒë√≥. Overthinking n√≥ c·ª© nh∆∞ m·ªô...  \n",
       "3     √îi, ai m√† ch·∫≥ng c√≥ l√∫c m·∫Øc l·ªói ph·∫£i kh√¥ng b·∫°n?...  \n",
       "4     Ch√†o b·∫°n, m√¨nh hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n l√∫c n√†y. ...  \n",
       "...                                                 ...  \n",
       "5995  T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. Sau khi ra tr∆∞·ªùng, t...  \n",
       "5996  T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa b·∫°n. ƒê√¥i khi kho·∫£ng c√°ch ...  \n",
       "5997  ƒê·ª´ng t·ª± tr√°ch m√¨nh qu√° nhi·ªÅu nh√©. Ai trong ch√∫...  \n",
       "5998  C√≥ th·ªÉ b·∫°n ƒëang b·ªã stress ho·∫∑c thi·∫øu ng·ªß ƒë·∫•y. ...  \n",
       "5999  Chuy·ªán n√†y b√¨nh th∆∞·ªùng m√† b·∫°n ∆°i. Ai chuy·ªÉn c√¥...  \n",
       "\n",
       "[6000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_ragas(df):\n",
    "    '''\n",
    "    Converts a Pandas DataFrame into a Ragas-compatible dataset\n",
    "    \n",
    "    Inputs:\n",
    "        - df (Pandas DataFrame): The input DataFrame to be converted\n",
    "        \n",
    "    Returns:\n",
    "        - ragas_testset (Hugging Face Dataset): A Hugging Face dataset compatible with the Ragas framework\n",
    "    '''\n",
    "    # Ensure all text columns are strings and handle NaN values\n",
    "    text_columns = ['question', 'ground_truth', 'answer']\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "        \n",
    "    # Convert 'contexts' to a list of lists\n",
    "    df['contexts'] = df['contexts'].fillna('').astype(str).apply(lambda x: [x] if x else [])\n",
    "    \n",
    "    # Converting the DataFrame to a dictionary\n",
    "    data_dict = df[['question', 'contexts', 'answer', 'ground_truth']].to_dict('list')\n",
    "    \n",
    "    # Loading the dictionary as a Hugging Face dataset\n",
    "    ragas_testset = Dataset.from_dict(data_dict)\n",
    "    \n",
    "    return ragas_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_testset = pandas_to_ragas(df = df_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "#             model=\"gemini-2.0-flash\",\n",
    "#             google_api_key=\"AIzaSyB17vRD3BlCe0gzOCbvbrgwwC7zVTXlbZo\",\n",
    "#             temperature=Config.Model.TEMPERATURE,\n",
    "#             max_tokens=Config.Model.MAX_TOKENS,\n",
    "#             timeout=None,\n",
    "#             max_retries=5,\n",
    "#         ))\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=Config.Model.EMBEDDINGS)\n",
    "# run_config = RunConfig(timeout=200, max_retries=10, max_wait = 100, max_workers=1)\n",
    "\n",
    "# # Generating the Ragas scores\n",
    "# ragas_scores = evaluate(\n",
    "#     dataset = ragas_testset,\n",
    "#     llm = llm,\n",
    "#     embeddings = embedding_model,\n",
    "#     metrics = [\n",
    "#         faithfulness, # xem c√¢u tr·∫£ l·ªùi c√≥ trung th·ª±c v·ªõi c√°c contexts kh√¥ng.\n",
    "#         answer_relevancy, # c√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "#         context_precision, # contexts m√† model truy xu·∫•t c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "#         answer_correctness, # c√¢u tr·∫£ l·ªùi c·ªßa model v·ªõi ground_truth\n",
    "#     ],\n",
    "#     run_config = run_config\n",
    "# )\n",
    "# # Converting the Ragas scores to a Pandas DataFrame\n",
    "# df_ragas_scores = ragas_scores.to_pandas()\n",
    "\n",
    "# # Saving the Ragas scores to a CSV file\n",
    "\n",
    "# df_ragas_scores.to_excel('data/ragas_scores.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= C·∫§U H√åNH =======\n",
    "chunk_size = 3\n",
    "\n",
    "save_dir = \"data/evaluate\"\n",
    "list_key = [\n",
    "    \"AIzaSyBSLdACUAR5srrD_yoolWKtIZlIk5JtMSo\",\n",
    "    \"AIzaSyB17vRD3BlCe0gzOCbvbrgwwC7zVTXlbZo\",\n",
    "    \"AIzaSyCVA6ctW4cXNUzwUqYkR6pWbBSdh19zwvA\",\n",
    "    \"AIzaSyCNLh5HhlIUovo8_de1RWg1jAx2Iq4Yo8g\",\n",
    "    \"AIzaSyD_d2NNsNxVhWLK_d2yjnEQuyTNUECi1Ns\",\n",
    "    \"AIzaSyCw371rlLG4FqlRan4C0rD280sqVga-zE4\",\n",
    "    \"AIzaSyBctBtlbRv4aJ5cvJRZNK_sfPiBY8-6KoY\",\n",
    "    \"AIzaSyAMKQvJs5hAup1JUNl3G29dt24m5mRLgiE\",\n",
    "    \"AIzaSyDaVCYIC-j6BoBe4VEWPRMWnR7hTu9puZo\",\n",
    "    \"AIzaSyBfmOEpr9mdfyEimLW1wQh9Ik4drMAdyF8\",\n",
    "    \"AIzaSyCZ6lZNrFesfPtSkixvmaH7b8TX-UMUVBg\",\n",
    "]\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_chunks = (len(df_testset) + chunk_size - 1) // chunk_size\n",
    "\n",
    "# EMBEDDINGS: ch·ªâ c·∫ßn kh·ªüi t·∫°o 1 l·∫ßn\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=Config.Model.EMBEDDINGS)\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=200,\n",
    "    max_retries=20,\n",
    "    max_wait=200,\n",
    "    max_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 0/2000 [00:00<?, ?it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:38<00:00,  8.17s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 1/2000 [01:39<55:12:32, 99.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 1 ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: AIzaSyBSLdACUAR5srrD_yoolWKtIZlIk5JtMSo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "].\n",
      "Evaluating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7/12 [00:39<00:28,  5.69s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 1/2000 [02:20<77:59:40, 140.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     15\u001b[39m llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n\u001b[32m     16\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     google_api_key=selected_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     max_retries=\u001b[32m5\u001b[39m,\n\u001b[32m     22\u001b[39m ))\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# üëâ ƒê√°nh gi√°\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m ragas_scores_chunk = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mragas_testset_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_correctness\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# üëâ Ghi k·∫øt qu·∫£ ra file Excel\u001b[39;00m\n\u001b[32m     39\u001b[39m df_scores_chunk = ragas_scores_chunk.to_pandas()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\evaluation.py:294\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    291\u001b[39m scores: t.List[t.Dict[\u001b[38;5;28mstr\u001b[39m, t.Any]] = []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results == []:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:31\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     29\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:93\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     91\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:116\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m     heappop(scheduled)\n\u001b[32m    111\u001b[39m timeout = (\n\u001b[32m    112\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    114\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    119\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\selectors.py:323\u001b[39m, in \u001b[36mSelectSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    321\u001b[39m ready = []\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     r, w, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\selectors.py:314\u001b[39m, in \u001b[36mSelectSelector._select\u001b[39m\u001b[34m(self, r, w, _, timeout)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     r, w, x = \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w + x, []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "].\n"
     ]
    }
   ],
   "source": [
    "# ======= X·ª¨ L√ù THEO CHUNK V√Ä XOAY V√íNG API KEY =======\n",
    "for i in tqdm(range(chunk_start, 2000), desc=\"ƒêang ch·∫°y c√°c chunk\"):\n",
    "    chunk_df = df_testset.iloc[i * chunk_size:(i + 1) * chunk_size].reset_index(drop=True)\n",
    "    if chunk_df.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # üëâ Chuy·ªÉn DataFrame chunk sang ragas_testset (theo ƒë√∫ng h√†m c·ªßa b·∫°n)\n",
    "        ragas_testset_chunk = pandas_to_ragas(chunk_df)\n",
    "\n",
    "        # üëâ Ch·ªçn API key theo round-robin\n",
    "        selected_key = list_key[i % len(list_key)]\n",
    "\n",
    "        # üëâ T·∫°o LLM wrapper t∆∞∆°ng ·ª©ng\n",
    "        llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            google_api_key=selected_key,\n",
    "            temperature=Config.Model.TEMPERATURE,\n",
    "            max_tokens=Config.Model.MAX_TOKENS,\n",
    "            timeout=None,\n",
    "            max_retries=5,\n",
    "        ))\n",
    "\n",
    "        # üëâ ƒê√°nh gi√°\n",
    "        ragas_scores_chunk = evaluate(\n",
    "            dataset=ragas_testset_chunk,\n",
    "            llm=llm,\n",
    "            embeddings=embedding_model,\n",
    "            metrics=[\n",
    "                faithfulness,\n",
    "                answer_relevancy,\n",
    "                context_precision,\n",
    "                answer_correctness\n",
    "            ],\n",
    "            run_config=run_config\n",
    "        )\n",
    "\n",
    "        # üëâ Ghi k·∫øt qu·∫£ ra file Excel\n",
    "        df_scores_chunk = ragas_scores_chunk.to_pandas()\n",
    "        # df_scores_chunk[\"chunk_index\"] = i\n",
    "        output_path = os.path.join(save_dir, f\"ragas_score_chunk_{i + 1}.xlsx\")\n",
    "        df_scores_chunk.to_excel(output_path, index=False)\n",
    "\n",
    "        print(f\"‚úÖ Chunk {i + 1} ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: {selected_key}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói ·ªü chunk {i + 1} v·ªõi key {selected_key}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em m·ªõi chia tay ng∆∞·ªùi y√™u ƒë∆∞·ª£c 2 th√°ng, nh∆∞ng ...</td>\n",
       "      <td>[Question: L√†m sao ƒë·ªÉ quay tr·ªü l·∫°i? T√¥i v√† em ...</td>\n",
       "      <td>Nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u gh√™ ü•∫ Chia ...</td>\n",
       "      <td>H√£y cho ph√©p b·∫£n th√¢n ƒë∆∞·ª£c bu·ªìn. ƒê·ª´ng c·ªë g·∫Øng ...</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.842030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M√¨nh v√† ng∆∞·ªùi y√™u m√¨nh y√™u nhau ƒë∆∞·ª£c 2 nƒÉm r·ªìi...</td>\n",
       "      <td>[Question: M√¨nh v·ªõi b·ªì m√¨nh quen nhau g·∫ßn 2 nƒÉ...</td>\n",
       "      <td>T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa c·∫≠u n√®. Y√™u l√¢u m√† c·ª© ƒë·ªÅu...</td>\n",
       "      <td>L√™n k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn ƒëi ng·∫Øn ng√†y ƒë·∫øn m...</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em c·∫£m th·∫•y kh√≥ khƒÉn khi m·ªü l√≤ng v√† tin t∆∞·ªüng ...</td>\n",
       "      <td>[Question: Em mong nh·∫≠n ƒë∆∞·ª£c s·ª± t∆∞ v·∫•n c·ªßa c√°c...</td>\n",
       "      <td>T·ªõ hi·ªÉu m√†, sau nh·ªØng t·ªïn th∆∞∆°ng t·ª´ gia ƒë√¨nh t...</td>\n",
       "      <td>Th·∫•u hi·ªÉu v√† ch·∫•p nh·∫≠n qu√° kh·ª© l√† b∆∞·ªõc ƒë·∫ßu ti√™...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.891097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Em m·ªõi chia tay ng∆∞·ªùi y√™u ƒë∆∞·ª£c 2 th√°ng, nh∆∞ng ...   \n",
       "1  M√¨nh v√† ng∆∞·ªùi y√™u m√¨nh y√™u nhau ƒë∆∞·ª£c 2 nƒÉm r·ªìi...   \n",
       "2  Em c·∫£m th·∫•y kh√≥ khƒÉn khi m·ªü l√≤ng v√† tin t∆∞·ªüng ...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Question: L√†m sao ƒë·ªÉ quay tr·ªü l·∫°i? T√¥i v√† em ...   \n",
       "1  [Question: M√¨nh v·ªõi b·ªì m√¨nh quen nhau g·∫ßn 2 nƒÉ...   \n",
       "2  [Question: Em mong nh·∫≠n ƒë∆∞·ª£c s·ª± t∆∞ v·∫•n c·ªßa c√°c...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u gh√™ ü•∫ Chia ...   \n",
       "1  T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa c·∫≠u n√®. Y√™u l√¢u m√† c·ª© ƒë·ªÅu...   \n",
       "2  T·ªõ hi·ªÉu m√†, sau nh·ªØng t·ªïn th∆∞∆°ng t·ª´ gia ƒë√¨nh t...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  H√£y cho ph√©p b·∫£n th√¢n ƒë∆∞·ª£c bu·ªìn. ƒê·ª´ng c·ªë g·∫Øng ...       0.04878   \n",
       "1  L√™n k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn ƒëi ng·∫Øn ng√†y ƒë·∫øn m...       0.50000   \n",
       "2  Th·∫•u hi·ªÉu v√† ch·∫•p nh·∫≠n qu√° kh·ª© l√† b∆∞·ªõc ƒë·∫ßu ti√™...       1.00000   \n",
       "\n",
       "   answer_relevancy  context_precision  answer_correctness  \n",
       "0          0.842030                1.0            0.354633  \n",
       "1          0.831000                1.0            0.273304  \n",
       "2          0.891097                1.0            0.273067  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ragas_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
