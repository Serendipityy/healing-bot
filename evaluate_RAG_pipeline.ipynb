{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from ragas import evaluate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from ragbase.config import Config\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.run_config import RunConfig\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.metrics import (\n",
    "    faithfulness, # xem câu trả lời có trung thực với các contexts không.\n",
    "    answer_relevancy, # câu trả lời có liên quan đến câu hỏi không\n",
    "    context_precision, # contexts mà model truy xuất có liên quan đến câu hỏi không\n",
    "    context_recall,\n",
    "    context_entity_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness, # câu trả lời của model với ground_truth\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset = pd.read_excel('./data/test_dataset_3000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em mới chia tay người yêu được 2 tháng, nhưng ...</td>\n",
       "      <td>Question: Làm sao để quay trở lại? Tôi và em m...</td>\n",
       "      <td>Nghe cậu nói mà tớ thấy thương cậu ghê 🥺 Chia ...</td>\n",
       "      <td>Hãy cho phép bản thân được buồn. Đừng cố gắng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mình và người yêu mình yêu nhau được 2 năm rồi...</td>\n",
       "      <td>Question: Mình với bồ mình quen nhau gần 2 năm...</td>\n",
       "      <td>Tớ hiểu cảm giác của cậu nè. Yêu lâu mà cứ đều...</td>\n",
       "      <td>Lên kế hoạch cho một chuyến đi ngắn ngày đến m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em cảm thấy khó khăn khi mở lòng và tin tưởng ...</td>\n",
       "      <td>Question: Em mong nhận được sự tư vấn của các ...</td>\n",
       "      <td>Tớ hiểu mà, sau những tổn thương từ gia đình t...</td>\n",
       "      <td>Thấu hiểu và chấp nhận quá khứ là bước đầu tiê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dạo gần đây mình cảm thấy mọi thứ xung quanh t...</td>\n",
       "      <td>Question: Chào mn ạ, dạo gần đây mình stress q...</td>\n",
       "      <td>Ui da, nghe cậu kể mà tớ thấy nhói lòng ghê 🥺....</td>\n",
       "      <td>Hãy nhớ rằng, cảm giác này là tạm thời. Dành t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Em là sinh viên năm nhất, mới lên thành phố họ...</td>\n",
       "      <td>Question: Lên Đại Học Nên Quan Trọng Mối Quan ...</td>\n",
       "      <td>Nghe em kể mà thấy thương ghê 🥺. Tớ hiểu cảm g...</td>\n",
       "      <td>Tham gia các câu lạc bộ, đội nhóm ở trường. Đâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>Em đang học lớp 9 và cảm thấy rất áp lực vì sắ...</td>\n",
       "      <td>Question: Mọi người ơi cho em hỏi ạ, em năm na...</td>\n",
       "      <td>Nghe cậu kể mà tớ thấy thương ghê 🥺. Tớ hiểu c...</td>\n",
       "      <td>Dành thời gian cho những hoạt động thư giãn, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>Dạo gần đây mình cảm thấy khó khăn trong việc ...</td>\n",
       "      <td>Question: Làm Thế Nào Để Thay Đổi Bố Mình? Xin...</td>\n",
       "      <td>Tớ hiểu mà, cái cảm giác muốn thể hiện tình cả...</td>\n",
       "      <td>Hãy bắt đầu từ những hành động nhỏ, ví dụ như ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>Em đang rất băn khoăn giữa việc tiếp tục theo ...</td>\n",
       "      <td>Em vừa tốt nghiệp, cũng đã tìm được việc làm. ...</td>\n",
       "      <td>Nghe cậu kể mà tớ thấy quen ghê á, giống như t...</td>\n",
       "      <td>Hãy thử tìm cách dung hòa cả hai! Bạn có thể l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Em và người yêu em đã chia tay được 3 tháng. A...</td>\n",
       "      <td>Question: Cần giúp chuyện tình yêu. Chuyện là ...</td>\n",
       "      <td>Nghe cậu kể mà tớ thấy thương ghê 🥺 Yêu nhau t...</td>\n",
       "      <td>Trước khi quyết định liên lạc, hãy dành thời g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>Mình cảm thấy rất áp lực khi liên tục bị so sá...</td>\n",
       "      <td>Question: Mình luôn cảm thấy tự ti về ngoại hì...</td>\n",
       "      <td>Nghe cậu kể mà tớ thấy thương ghê 🥺 Tớ hiểu cả...</td>\n",
       "      <td>Hãy tập trung vào những điểm mạnh và thành tựu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3009 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Em mới chia tay người yêu được 2 tháng, nhưng ...   \n",
       "1     Mình và người yêu mình yêu nhau được 2 năm rồi...   \n",
       "2     Em cảm thấy khó khăn khi mở lòng và tin tưởng ...   \n",
       "3     Dạo gần đây mình cảm thấy mọi thứ xung quanh t...   \n",
       "4     Em là sinh viên năm nhất, mới lên thành phố họ...   \n",
       "...                                                 ...   \n",
       "3004  Em đang học lớp 9 và cảm thấy rất áp lực vì sắ...   \n",
       "3005  Dạo gần đây mình cảm thấy khó khăn trong việc ...   \n",
       "3006  Em đang rất băn khoăn giữa việc tiếp tục theo ...   \n",
       "3007  Em và người yêu em đã chia tay được 3 tháng. A...   \n",
       "3008  Mình cảm thấy rất áp lực khi liên tục bị so sá...   \n",
       "\n",
       "                                               contexts  \\\n",
       "0     Question: Làm sao để quay trở lại? Tôi và em m...   \n",
       "1     Question: Mình với bồ mình quen nhau gần 2 năm...   \n",
       "2     Question: Em mong nhận được sự tư vấn của các ...   \n",
       "3     Question: Chào mn ạ, dạo gần đây mình stress q...   \n",
       "4     Question: Lên Đại Học Nên Quan Trọng Mối Quan ...   \n",
       "...                                                 ...   \n",
       "3004  Question: Mọi người ơi cho em hỏi ạ, em năm na...   \n",
       "3005  Question: Làm Thế Nào Để Thay Đổi Bố Mình? Xin...   \n",
       "3006  Em vừa tốt nghiệp, cũng đã tìm được việc làm. ...   \n",
       "3007  Question: Cần giúp chuyện tình yêu. Chuyện là ...   \n",
       "3008  Question: Mình luôn cảm thấy tự ti về ngoại hì...   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     Nghe cậu nói mà tớ thấy thương cậu ghê 🥺 Chia ...   \n",
       "1     Tớ hiểu cảm giác của cậu nè. Yêu lâu mà cứ đều...   \n",
       "2     Tớ hiểu mà, sau những tổn thương từ gia đình t...   \n",
       "3     Ui da, nghe cậu kể mà tớ thấy nhói lòng ghê 🥺....   \n",
       "4     Nghe em kể mà thấy thương ghê 🥺. Tớ hiểu cảm g...   \n",
       "...                                                 ...   \n",
       "3004  Nghe cậu kể mà tớ thấy thương ghê 🥺. Tớ hiểu c...   \n",
       "3005  Tớ hiểu mà, cái cảm giác muốn thể hiện tình cả...   \n",
       "3006  Nghe cậu kể mà tớ thấy quen ghê á, giống như t...   \n",
       "3007  Nghe cậu kể mà tớ thấy thương ghê 🥺 Yêu nhau t...   \n",
       "3008  Nghe cậu kể mà tớ thấy thương ghê 🥺 Tớ hiểu cả...   \n",
       "\n",
       "                                           ground_truth  \n",
       "0     Hãy cho phép bản thân được buồn. Đừng cố gắng ...  \n",
       "1     Lên kế hoạch cho một chuyến đi ngắn ngày đến m...  \n",
       "2     Thấu hiểu và chấp nhận quá khứ là bước đầu tiê...  \n",
       "3     Hãy nhớ rằng, cảm giác này là tạm thời. Dành t...  \n",
       "4     Tham gia các câu lạc bộ, đội nhóm ở trường. Đâ...  \n",
       "...                                                 ...  \n",
       "3004  Dành thời gian cho những hoạt động thư giãn, g...  \n",
       "3005  Hãy bắt đầu từ những hành động nhỏ, ví dụ như ...  \n",
       "3006  Hãy thử tìm cách dung hòa cả hai! Bạn có thể l...  \n",
       "3007  Trước khi quyết định liên lạc, hãy dành thời g...  \n",
       "3008  Hãy tập trung vào những điểm mạnh và thành tựu...  \n",
       "\n",
       "[3009 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_ragas(df):\n",
    "    '''\n",
    "    Converts a Pandas DataFrame into a Ragas-compatible dataset\n",
    "    \n",
    "    Inputs:\n",
    "        - df (Pandas DataFrame): The input DataFrame to be converted\n",
    "        \n",
    "    Returns:\n",
    "        - ragas_testset (Hugging Face Dataset): A Hugging Face dataset compatible with the Ragas framework\n",
    "    '''\n",
    "    # Ensure all text columns are strings and handle NaN values\n",
    "    text_columns = ['question', 'ground_truth', 'answer']\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "        \n",
    "    # Convert 'contexts' to a list of lists\n",
    "    df['contexts'] = df['contexts'].fillna('').astype(str).apply(lambda x: [x] if x else [])\n",
    "    \n",
    "    # Converting the DataFrame to a dictionary\n",
    "    data_dict = df[['question', 'contexts', 'answer', 'ground_truth']].to_dict('list')\n",
    "    \n",
    "    # Loading the dictionary as a Hugging Face dataset\n",
    "    ragas_testset = Dataset.from_dict(data_dict)\n",
    "    \n",
    "    return ragas_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_testset = pandas_to_ragas(df = df_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "#             model=\"gemini-2.0-flash\",\n",
    "#             google_api_key=\"AIzaSyB17vRD3BlCe0gzOCbvbrgwwC7zVTXlbZo\",\n",
    "#             temperature=Config.Model.TEMPERATURE,\n",
    "#             max_tokens=Config.Model.MAX_TOKENS,\n",
    "#             timeout=None,\n",
    "#             max_retries=5,\n",
    "#         ))\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=Config.Model.EMBEDDINGS)\n",
    "# run_config = RunConfig(timeout=200, max_retries=10, max_wait = 100, max_workers=1)\n",
    "\n",
    "# # Generating the Ragas scores\n",
    "# ragas_scores = evaluate(\n",
    "#     dataset = ragas_testset,\n",
    "#     llm = llm,\n",
    "#     embeddings = embedding_model,\n",
    "#     metrics = [\n",
    "#         faithfulness, # xem câu trả lời có trung thực với các contexts không.\n",
    "#         answer_relevancy, # câu trả lời có liên quan đến câu hỏi không\n",
    "#         context_precision, # contexts mà model truy xuất có liên quan đến câu hỏi không\n",
    "#         answer_correctness, # câu trả lời của model với ground_truth\n",
    "#     ],\n",
    "#     run_config = run_config\n",
    "# )\n",
    "# # Converting the Ragas scores to a Pandas DataFrame\n",
    "# df_ragas_scores = ragas_scores.to_pandas()\n",
    "\n",
    "# # Saving the Ragas scores to a CSV file\n",
    "\n",
    "# df_ragas_scores.to_excel('data/ragas_scores.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= CẤU HÌNH =======\n",
    "chunk_size = 3\n",
    "\n",
    "save_dir = \"data/evaluate\"\n",
    "list_key = [\n",
    "    \"AIzaSyBSLdACUAR5srrD_yoolWKtIZlIk5JtMSo\",\n",
    "    \"AIzaSyB17vRD3BlCe0gzOCbvbrgwwC7zVTXlbZo\",\n",
    "    \"AIzaSyCVA6ctW4cXNUzwUqYkR6pWbBSdh19zwvA\",\n",
    "    \"AIzaSyCNLh5HhlIUovo8_de1RWg1jAx2Iq4Yo8g\",\n",
    "    \"AIzaSyD_d2NNsNxVhWLK_d2yjnEQuyTNUECi1Ns\",\n",
    "    \"AIzaSyCw371rlLG4FqlRan4C0rD280sqVga-zE4\",\n",
    "    \"AIzaSyBctBtlbRv4aJ5cvJRZNK_sfPiBY8-6KoY\",\n",
    "    \"AIzaSyAMKQvJs5hAup1JUNl3G29dt24m5mRLgiE\",\n",
    "    \"AIzaSyDaVCYIC-j6BoBe4VEWPRMWnR7hTu9puZo\"\n",
    "]\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_chunks = (len(df_testset) + chunk_size - 1) // chunk_size\n",
    "\n",
    "# EMBEDDINGS: chỉ cần khởi tạo 1 lần\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=Config.Model.EMBEDDINGS)\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=200,\n",
    "    max_retries=20,\n",
    "    max_wait=200,\n",
    "    max_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_start = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang chạy các chunk:   0%|          | 0/990 [00:00<?, ?it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 42\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|██████████| 12/12 [01:44<00:00,  8.73s/it]\n",
      "Đang chạy các chunk:   0%|          | 1/990 [01:46<29:17:07, 106.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 14 đã xử lý xong với API key: AIzaSyD_d2NNsNxVhWLK_d2yjnEQuyTNUECi1Ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|██████████| 12/12 [01:45<00:00,  8.82s/it]\n",
      "Đang chạy các chunk:   0%|          | 2/990 [03:34<29:25:51, 107.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 15 đã xử lý xong với API key: AIzaSyCw371rlLG4FqlRan4C0rD280sqVga-zE4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|██████████| 12/12 [01:38<00:00,  8.22s/it]\n",
      "Đang chạy các chunk:   0%|          | 3/990 [05:14<28:32:40, 104.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 16 đã xử lý xong với API key: AIzaSyBctBtlbRv4aJ5cvJRZNK_sfPiBY8-6KoY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|██████████| 12/12 [02:00<00:00, 10.07s/it]\n",
      "Đang chạy các chunk:   0%|          | 4/990 [07:16<30:28:14, 111.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 17 đã xử lý xong với API key: AIzaSyAMKQvJs5hAup1JUNl3G29dt24m5mRLgiE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|██████████| 12/12 [01:42<00:00,  8.53s/it]\n",
      "Đang chạy các chunk:   1%|          | 5/990 [09:00<29:41:29, 108.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk 18 đã xử lý xong với API key: AIzaSyDaVCYIC-j6BoBe4VEWPRMWnR7hTu9puZo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  17%|█▋        | 2/12 [00:12<01:01,  6.19s/it]\n",
      "Đang chạy các chunk:   1%|          | 5/990 [09:13<30:17:35, 110.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     15\u001b[39m llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n\u001b[32m     16\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     google_api_key=selected_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     max_retries=\u001b[32m5\u001b[39m,\n\u001b[32m     22\u001b[39m ))\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 👉 Đánh giá\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m ragas_scores_chunk = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mragas_testset_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_correctness\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 👉 Ghi kết quả ra file Excel\u001b[39;00m\n\u001b[32m     39\u001b[39m df_scores_chunk = ragas_scores_chunk.to_pandas()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\evaluation.py:294\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    291\u001b[39m scores: t.List[t.Dict[\u001b[38;5;28mstr\u001b[39m, t.Any]] = []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results == []:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:31\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     29\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:93\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     91\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:116\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m     heappop(scheduled)\n\u001b[32m    111\u001b[39m timeout = (\n\u001b[32m    112\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    114\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    119\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\selectors.py:323\u001b[39m, in \u001b[36mSelectSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    321\u001b[39m ready = []\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     r, w, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\selectors.py:314\u001b[39m, in \u001b[36mSelectSelector._select\u001b[39m\u001b[34m(self, r, w, _, timeout)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     r, w, x = \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w + x, []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[3]: AssertionError(LLM must be set)\n",
      "Exception raised in Job[4]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[5]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[6]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[7]: AssertionError(LLM must be set)\n",
      "Exception raised in Job[8]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[9]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[10]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[11]: AssertionError(LLM must be set)\n"
     ]
    }
   ],
   "source": [
    "# ======= XỬ LÝ THEO CHUNK VÀ XOAY VÒNG API KEY =======\n",
    "for i in tqdm(range(chunk_start, num_chunks), desc=\"Đang chạy các chunk\"):\n",
    "    chunk_df = df_testset.iloc[i * chunk_size:(i + 1) * chunk_size].reset_index(drop=True)\n",
    "    if chunk_df.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 👉 Chuyển DataFrame chunk sang ragas_testset (theo đúng hàm của bạn)\n",
    "        ragas_testset_chunk = pandas_to_ragas(chunk_df)\n",
    "\n",
    "        # 👉 Chọn API key theo round-robin\n",
    "        selected_key = list_key[i % len(list_key)]\n",
    "\n",
    "        # 👉 Tạo LLM wrapper tương ứng\n",
    "        llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            google_api_key=selected_key,\n",
    "            temperature=Config.Model.TEMPERATURE,\n",
    "            max_tokens=Config.Model.MAX_TOKENS,\n",
    "            timeout=None,\n",
    "            max_retries=5,\n",
    "        ))\n",
    "\n",
    "        # 👉 Đánh giá\n",
    "        ragas_scores_chunk = evaluate(\n",
    "            dataset=ragas_testset_chunk,\n",
    "            llm=llm,\n",
    "            embeddings=embedding_model,\n",
    "            metrics=[\n",
    "                faithfulness,\n",
    "                answer_relevancy,\n",
    "                context_precision,\n",
    "                answer_correctness\n",
    "            ],\n",
    "            run_config=run_config\n",
    "        )\n",
    "\n",
    "        # 👉 Ghi kết quả ra file Excel\n",
    "        df_scores_chunk = ragas_scores_chunk.to_pandas()\n",
    "        # df_scores_chunk[\"chunk_index\"] = i\n",
    "        output_path = os.path.join(save_dir, f\"ragas_score_chunk_{i + 1}.xlsx\")\n",
    "        df_scores_chunk.to_excel(output_path, index=False)\n",
    "\n",
    "        print(f\"✅ Chunk {i + 1} đã xử lý xong với API key: {selected_key}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi ở chunk {i + 1} với key {selected_key}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em mới chia tay người yêu được 2 tháng, nhưng ...</td>\n",
       "      <td>[Question: Làm sao để quay trở lại? Tôi và em ...</td>\n",
       "      <td>Nghe cậu nói mà tớ thấy thương cậu ghê 🥺 Chia ...</td>\n",
       "      <td>Hãy cho phép bản thân được buồn. Đừng cố gắng ...</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.842030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mình và người yêu mình yêu nhau được 2 năm rồi...</td>\n",
       "      <td>[Question: Mình với bồ mình quen nhau gần 2 nă...</td>\n",
       "      <td>Tớ hiểu cảm giác của cậu nè. Yêu lâu mà cứ đều...</td>\n",
       "      <td>Lên kế hoạch cho một chuyến đi ngắn ngày đến m...</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em cảm thấy khó khăn khi mở lòng và tin tưởng ...</td>\n",
       "      <td>[Question: Em mong nhận được sự tư vấn của các...</td>\n",
       "      <td>Tớ hiểu mà, sau những tổn thương từ gia đình t...</td>\n",
       "      <td>Thấu hiểu và chấp nhận quá khứ là bước đầu tiê...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.891097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Em mới chia tay người yêu được 2 tháng, nhưng ...   \n",
       "1  Mình và người yêu mình yêu nhau được 2 năm rồi...   \n",
       "2  Em cảm thấy khó khăn khi mở lòng và tin tưởng ...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Question: Làm sao để quay trở lại? Tôi và em ...   \n",
       "1  [Question: Mình với bồ mình quen nhau gần 2 nă...   \n",
       "2  [Question: Em mong nhận được sự tư vấn của các...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Nghe cậu nói mà tớ thấy thương cậu ghê 🥺 Chia ...   \n",
       "1  Tớ hiểu cảm giác của cậu nè. Yêu lâu mà cứ đều...   \n",
       "2  Tớ hiểu mà, sau những tổn thương từ gia đình t...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  Hãy cho phép bản thân được buồn. Đừng cố gắng ...       0.04878   \n",
       "1  Lên kế hoạch cho một chuyến đi ngắn ngày đến m...       0.50000   \n",
       "2  Thấu hiểu và chấp nhận quá khứ là bước đầu tiê...       1.00000   \n",
       "\n",
       "   answer_relevancy  context_precision  answer_correctness  \n",
       "0          0.842030                1.0            0.354633  \n",
       "1          0.831000                1.0            0.273304  \n",
       "2          0.891097                1.0            0.273067  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ragas_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
