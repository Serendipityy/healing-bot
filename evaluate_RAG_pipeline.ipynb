{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from ragas import evaluate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from ragbase.config import Config\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.run_config import RunConfig\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.metrics import (\n",
    "    faithfulness, # xem c√¢u tr·∫£ l·ªùi c√≥ trung th·ª±c v·ªõi c√°c contexts kh√¥ng.\n",
    "    answer_relevancy, # c√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "    context_precision, # contexts m√† model truy xu·∫•t c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "    context_recall,\n",
    "    context_entity_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness, # c√¢u tr·∫£ l·ªùi c·ªßa model v·ªõi ground_truth\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset = pd.read_excel('./data/test_dataset_3000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em m·ªõi chia tay ng∆∞·ªùi y√™u ƒë∆∞·ª£c 2 th√°ng, nh∆∞ng ...</td>\n",
       "      <td>Question: L√†m sao ƒë·ªÉ quay tr·ªü l·∫°i? T√¥i v√† em m...</td>\n",
       "      <td>Nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u gh√™ ü•∫ Chia ...</td>\n",
       "      <td>H√£y cho ph√©p b·∫£n th√¢n ƒë∆∞·ª£c bu·ªìn. ƒê·ª´ng c·ªë g·∫Øng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M√¨nh v√† ng∆∞·ªùi y√™u m√¨nh y√™u nhau ƒë∆∞·ª£c 2 nƒÉm r·ªìi...</td>\n",
       "      <td>Question: M√¨nh v·ªõi b·ªì m√¨nh quen nhau g·∫ßn 2 nƒÉm...</td>\n",
       "      <td>T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa c·∫≠u n√®. Y√™u l√¢u m√† c·ª© ƒë·ªÅu...</td>\n",
       "      <td>L√™n k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn ƒëi ng·∫Øn ng√†y ƒë·∫øn m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em c·∫£m th·∫•y kh√≥ khƒÉn khi m·ªü l√≤ng v√† tin t∆∞·ªüng ...</td>\n",
       "      <td>Question: Em mong nh·∫≠n ƒë∆∞·ª£c s·ª± t∆∞ v·∫•n c·ªßa c√°c ...</td>\n",
       "      <td>T·ªõ hi·ªÉu m√†, sau nh·ªØng t·ªïn th∆∞∆°ng t·ª´ gia ƒë√¨nh t...</td>\n",
       "      <td>Th·∫•u hi·ªÉu v√† ch·∫•p nh·∫≠n qu√° kh·ª© l√† b∆∞·ªõc ƒë·∫ßu ti√™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D·∫°o g·∫ßn ƒë√¢y m√¨nh c·∫£m th·∫•y m·ªçi th·ª© xung quanh t...</td>\n",
       "      <td>Question: Ch√†o mn ·∫°, d·∫°o g·∫ßn ƒë√¢y m√¨nh stress q...</td>\n",
       "      <td>Ui da, nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y nh√≥i l√≤ng gh√™ ü•∫....</td>\n",
       "      <td>H√£y nh·ªõ r·∫±ng, c·∫£m gi√°c n√†y l√† t·∫°m th·ªùi. D√†nh t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Em l√† sinh vi√™n nƒÉm nh·∫•t, m·ªõi l√™n th√†nh ph·ªë h·ªç...</td>\n",
       "      <td>Question: L√™n ƒê·∫°i H·ªçc N√™n Quan Tr·ªçng M·ªëi Quan ...</td>\n",
       "      <td>Nghe em k·ªÉ m√† th·∫•y th∆∞∆°ng gh√™ ü•∫. T·ªõ hi·ªÉu c·∫£m g...</td>\n",
       "      <td>Tham gia c√°c c√¢u l·∫°c b·ªô, ƒë·ªôi nh√≥m ·ªü tr∆∞·ªùng. ƒê√¢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>Em ƒëang h·ªçc l·ªõp 9 v√† c·∫£m th·∫•y r·∫•t √°p l·ª±c v√¨ s·∫Ø...</td>\n",
       "      <td>Question: M·ªçi ng∆∞·ªùi ∆°i cho em h·ªèi ·∫°, em nƒÉm na...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫. T·ªõ hi·ªÉu c...</td>\n",
       "      <td>D√†nh th·ªùi gian cho nh·ªØng ho·∫°t ƒë·ªông th∆∞ gi√£n, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>D·∫°o g·∫ßn ƒë√¢y m√¨nh c·∫£m th·∫•y kh√≥ khƒÉn trong vi·ªác ...</td>\n",
       "      <td>Question: L√†m Th·∫ø N√†o ƒê·ªÉ Thay ƒê·ªïi B·ªë M√¨nh? Xin...</td>\n",
       "      <td>T·ªõ hi·ªÉu m√†, c√°i c·∫£m gi√°c mu·ªën th·ªÉ hi·ªán t√¨nh c·∫£...</td>\n",
       "      <td>H√£y b·∫Øt ƒë·∫ßu t·ª´ nh·ªØng h√†nh ƒë·ªông nh·ªè, v√≠ d·ª• nh∆∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>Em ƒëang r·∫•t bƒÉn khoƒÉn gi·ªØa vi·ªác ti·∫øp t·ª•c theo ...</td>\n",
       "      <td>Em v·ª´a t·ªët nghi·ªáp, c≈©ng ƒë√£ t√¨m ƒë∆∞·ª£c vi·ªác l√†m. ...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y quen gh√™ √°, gi·ªëng nh∆∞ t...</td>\n",
       "      <td>H√£y th·ª≠ t√¨m c√°ch dung h√≤a c·∫£ hai! B·∫°n c√≥ th·ªÉ l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>Em v√† ng∆∞·ªùi y√™u em ƒë√£ chia tay ƒë∆∞·ª£c 3 th√°ng. A...</td>\n",
       "      <td>Question: C·∫ßn gi√∫p chuy·ªán t√¨nh y√™u. Chuy·ªán l√† ...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫ Y√™u nhau t...</td>\n",
       "      <td>Tr∆∞·ªõc khi quy·∫øt ƒë·ªãnh li√™n l·∫°c, h√£y d√†nh th·ªùi g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>M√¨nh c·∫£m th·∫•y r·∫•t √°p l·ª±c khi li√™n t·ª•c b·ªã so s√°...</td>\n",
       "      <td>Question: M√¨nh lu√¥n c·∫£m th·∫•y t·ª± ti v·ªÅ ngo·∫°i h√¨...</td>\n",
       "      <td>Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫ T·ªõ hi·ªÉu c·∫£...</td>\n",
       "      <td>H√£y t·∫≠p trung v√†o nh·ªØng ƒëi·ªÉm m·∫°nh v√† th√†nh t·ª±u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3009 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Em m·ªõi chia tay ng∆∞·ªùi y√™u ƒë∆∞·ª£c 2 th√°ng, nh∆∞ng ...   \n",
       "1     M√¨nh v√† ng∆∞·ªùi y√™u m√¨nh y√™u nhau ƒë∆∞·ª£c 2 nƒÉm r·ªìi...   \n",
       "2     Em c·∫£m th·∫•y kh√≥ khƒÉn khi m·ªü l√≤ng v√† tin t∆∞·ªüng ...   \n",
       "3     D·∫°o g·∫ßn ƒë√¢y m√¨nh c·∫£m th·∫•y m·ªçi th·ª© xung quanh t...   \n",
       "4     Em l√† sinh vi√™n nƒÉm nh·∫•t, m·ªõi l√™n th√†nh ph·ªë h·ªç...   \n",
       "...                                                 ...   \n",
       "3004  Em ƒëang h·ªçc l·ªõp 9 v√† c·∫£m th·∫•y r·∫•t √°p l·ª±c v√¨ s·∫Ø...   \n",
       "3005  D·∫°o g·∫ßn ƒë√¢y m√¨nh c·∫£m th·∫•y kh√≥ khƒÉn trong vi·ªác ...   \n",
       "3006  Em ƒëang r·∫•t bƒÉn khoƒÉn gi·ªØa vi·ªác ti·∫øp t·ª•c theo ...   \n",
       "3007  Em v√† ng∆∞·ªùi y√™u em ƒë√£ chia tay ƒë∆∞·ª£c 3 th√°ng. A...   \n",
       "3008  M√¨nh c·∫£m th·∫•y r·∫•t √°p l·ª±c khi li√™n t·ª•c b·ªã so s√°...   \n",
       "\n",
       "                                               contexts  \\\n",
       "0     Question: L√†m sao ƒë·ªÉ quay tr·ªü l·∫°i? T√¥i v√† em m...   \n",
       "1     Question: M√¨nh v·ªõi b·ªì m√¨nh quen nhau g·∫ßn 2 nƒÉm...   \n",
       "2     Question: Em mong nh·∫≠n ƒë∆∞·ª£c s·ª± t∆∞ v·∫•n c·ªßa c√°c ...   \n",
       "3     Question: Ch√†o mn ·∫°, d·∫°o g·∫ßn ƒë√¢y m√¨nh stress q...   \n",
       "4     Question: L√™n ƒê·∫°i H·ªçc N√™n Quan Tr·ªçng M·ªëi Quan ...   \n",
       "...                                                 ...   \n",
       "3004  Question: M·ªçi ng∆∞·ªùi ∆°i cho em h·ªèi ·∫°, em nƒÉm na...   \n",
       "3005  Question: L√†m Th·∫ø N√†o ƒê·ªÉ Thay ƒê·ªïi B·ªë M√¨nh? Xin...   \n",
       "3006  Em v·ª´a t·ªët nghi·ªáp, c≈©ng ƒë√£ t√¨m ƒë∆∞·ª£c vi·ªác l√†m. ...   \n",
       "3007  Question: C·∫ßn gi√∫p chuy·ªán t√¨nh y√™u. Chuy·ªán l√† ...   \n",
       "3008  Question: M√¨nh lu√¥n c·∫£m th·∫•y t·ª± ti v·ªÅ ngo·∫°i h√¨...   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     Nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u gh√™ ü•∫ Chia ...   \n",
       "1     T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa c·∫≠u n√®. Y√™u l√¢u m√† c·ª© ƒë·ªÅu...   \n",
       "2     T·ªõ hi·ªÉu m√†, sau nh·ªØng t·ªïn th∆∞∆°ng t·ª´ gia ƒë√¨nh t...   \n",
       "3     Ui da, nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y nh√≥i l√≤ng gh√™ ü•∫....   \n",
       "4     Nghe em k·ªÉ m√† th·∫•y th∆∞∆°ng gh√™ ü•∫. T·ªõ hi·ªÉu c·∫£m g...   \n",
       "...                                                 ...   \n",
       "3004  Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫. T·ªõ hi·ªÉu c...   \n",
       "3005  T·ªõ hi·ªÉu m√†, c√°i c·∫£m gi√°c mu·ªën th·ªÉ hi·ªán t√¨nh c·∫£...   \n",
       "3006  Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y quen gh√™ √°, gi·ªëng nh∆∞ t...   \n",
       "3007  Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫ Y√™u nhau t...   \n",
       "3008  Nghe c·∫≠u k·ªÉ m√† t·ªõ th·∫•y th∆∞∆°ng gh√™ ü•∫ T·ªõ hi·ªÉu c·∫£...   \n",
       "\n",
       "                                           ground_truth  \n",
       "0     H√£y cho ph√©p b·∫£n th√¢n ƒë∆∞·ª£c bu·ªìn. ƒê·ª´ng c·ªë g·∫Øng ...  \n",
       "1     L√™n k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn ƒëi ng·∫Øn ng√†y ƒë·∫øn m...  \n",
       "2     Th·∫•u hi·ªÉu v√† ch·∫•p nh·∫≠n qu√° kh·ª© l√† b∆∞·ªõc ƒë·∫ßu ti√™...  \n",
       "3     H√£y nh·ªõ r·∫±ng, c·∫£m gi√°c n√†y l√† t·∫°m th·ªùi. D√†nh t...  \n",
       "4     Tham gia c√°c c√¢u l·∫°c b·ªô, ƒë·ªôi nh√≥m ·ªü tr∆∞·ªùng. ƒê√¢...  \n",
       "...                                                 ...  \n",
       "3004  D√†nh th·ªùi gian cho nh·ªØng ho·∫°t ƒë·ªông th∆∞ gi√£n, g...  \n",
       "3005  H√£y b·∫Øt ƒë·∫ßu t·ª´ nh·ªØng h√†nh ƒë·ªông nh·ªè, v√≠ d·ª• nh∆∞ ...  \n",
       "3006  H√£y th·ª≠ t√¨m c√°ch dung h√≤a c·∫£ hai! B·∫°n c√≥ th·ªÉ l...  \n",
       "3007  Tr∆∞·ªõc khi quy·∫øt ƒë·ªãnh li√™n l·∫°c, h√£y d√†nh th·ªùi g...  \n",
       "3008  H√£y t·∫≠p trung v√†o nh·ªØng ƒëi·ªÉm m·∫°nh v√† th√†nh t·ª±u...  \n",
       "\n",
       "[3009 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_ragas(df):\n",
    "    '''\n",
    "    Converts a Pandas DataFrame into a Ragas-compatible dataset\n",
    "    \n",
    "    Inputs:\n",
    "        - df (Pandas DataFrame): The input DataFrame to be converted\n",
    "        \n",
    "    Returns:\n",
    "        - ragas_testset (Hugging Face Dataset): A Hugging Face dataset compatible with the Ragas framework\n",
    "    '''\n",
    "    # Ensure all text columns are strings and handle NaN values\n",
    "    text_columns = ['question', 'ground_truth', 'answer']\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "        \n",
    "    # Convert 'contexts' to a list of lists\n",
    "    df['contexts'] = df['contexts'].fillna('').astype(str).apply(lambda x: [x] if x else [])\n",
    "    \n",
    "    # Converting the DataFrame to a dictionary\n",
    "    data_dict = df[['question', 'contexts', 'answer', 'ground_truth']].to_dict('list')\n",
    "    \n",
    "    # Loading the dictionary as a Hugging Face dataset\n",
    "    ragas_testset = Dataset.from_dict(data_dict)\n",
    "    \n",
    "    return ragas_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_testset = pandas_to_ragas(df = df_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "#             model=\"gemini-2.0-flash\",\n",
    "#             google_api_key=\"AIzaSyB17vRD3BlCe0gzOCbvbrgwwC7zVTXlbZo\",\n",
    "#             temperature=Config.Model.TEMPERATURE,\n",
    "#             max_tokens=Config.Model.MAX_TOKENS,\n",
    "#             timeout=None,\n",
    "#             max_retries=5,\n",
    "#         ))\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=Config.Model.EMBEDDINGS)\n",
    "# run_config = RunConfig(timeout=200, max_retries=10, max_wait = 100, max_workers=1)\n",
    "\n",
    "# # Generating the Ragas scores\n",
    "# ragas_scores = evaluate(\n",
    "#     dataset = ragas_testset,\n",
    "#     llm = llm,\n",
    "#     embeddings = embedding_model,\n",
    "#     metrics = [\n",
    "#         faithfulness, # xem c√¢u tr·∫£ l·ªùi c√≥ trung th·ª±c v·ªõi c√°c contexts kh√¥ng.\n",
    "#         answer_relevancy, # c√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "#         context_precision, # contexts m√† model truy xu·∫•t c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng\n",
    "#         answer_correctness, # c√¢u tr·∫£ l·ªùi c·ªßa model v·ªõi ground_truth\n",
    "#     ],\n",
    "#     run_config = run_config\n",
    "# )\n",
    "# # Converting the Ragas scores to a Pandas DataFrame\n",
    "# df_ragas_scores = ragas_scores.to_pandas()\n",
    "\n",
    "# # Saving the Ragas scores to a CSV file\n",
    "\n",
    "# df_ragas_scores.to_excel('data/ragas_scores.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= C·∫§U H√åNH =======\n",
    "chunk_size = 3\n",
    "\n",
    "save_dir = \"data/evaluate\"\n",
    "list_key = [\n",
    "    \"AIzaSyBSLdACUAR5srrD_yoolWKtIZlIk5JtMSo\",\n",
    "    \"AIzaSyB17vRD3BlCe0gzOCbvbrgwwC7zVTXlbZo\",\n",
    "    \"AIzaSyCVA6ctW4cXNUzwUqYkR6pWbBSdh19zwvA\",\n",
    "    \"AIzaSyCNLh5HhlIUovo8_de1RWg1jAx2Iq4Yo8g\",\n",
    "    \"AIzaSyD_d2NNsNxVhWLK_d2yjnEQuyTNUECi1Ns\",\n",
    "    \"AIzaSyCw371rlLG4FqlRan4C0rD280sqVga-zE4\",\n",
    "    \"AIzaSyBctBtlbRv4aJ5cvJRZNK_sfPiBY8-6KoY\",\n",
    "    \"AIzaSyAMKQvJs5hAup1JUNl3G29dt24m5mRLgiE\",\n",
    "    \"AIzaSyDaVCYIC-j6BoBe4VEWPRMWnR7hTu9puZo\"\n",
    "]\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "num_chunks = (len(df_testset) + chunk_size - 1) // chunk_size\n",
    "\n",
    "# EMBEDDINGS: ch·ªâ c·∫ßn kh·ªüi t·∫°o 1 l·∫ßn\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=Config.Model.EMBEDDINGS)\n",
    "\n",
    "run_config = RunConfig(\n",
    "    timeout=200,\n",
    "    max_retries=20,\n",
    "    max_wait=200,\n",
    "    max_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_start = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 0/990 [00:00<?, ?it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 42\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:44<00:00,  8.73s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 1/990 [01:46<29:17:07, 106.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 14 ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: AIzaSyD_d2NNsNxVhWLK_d2yjnEQuyTNUECi1Ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:45<00:00,  8.82s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 2/990 [03:34<29:25:51, 107.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 15 ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: AIzaSyCw371rlLG4FqlRan4C0rD280sqVga-zE4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 39\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:38<00:00,  8.22s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 3/990 [05:14<28:32:40, 104.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 16 ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: AIzaSyBctBtlbRv4aJ5cvJRZNK_sfPiBY8-6KoY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 56\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [02:00<00:00, 10.07s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   0%|          | 4/990 [07:16<30:28:14, 111.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 17 ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: AIzaSyAMKQvJs5hAup1JUNl3G29dt24m5mRLgiE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "].\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:42<00:00,  8.53s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   1%|          | 5/990 [09:00<29:41:29, 108.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk 18 ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: AIzaSyDaVCYIC-j6BoBe4VEWPRMWnR7hTu9puZo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  17%|‚ñà‚ñã        | 2/12 [00:12<01:01,  6.19s/it]\n",
      "ƒêang ch·∫°y c√°c chunk:   1%|          | 5/990 [09:13<30:17:35, 110.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     15\u001b[39m llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n\u001b[32m     16\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     google_api_key=selected_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     max_retries=\u001b[32m5\u001b[39m,\n\u001b[32m     22\u001b[39m ))\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# üëâ ƒê√°nh gi√°\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m ragas_scores_chunk = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mragas_testset_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_correctness\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# üëâ Ghi k·∫øt qu·∫£ ra file Excel\u001b[39;00m\n\u001b[32m     39\u001b[39m df_scores_chunk = ragas_scores_chunk.to_pandas()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\evaluation.py:294\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    291\u001b[39m scores: t.List[t.Dict[\u001b[38;5;28mstr\u001b[39m, t.Any]] = []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results == []:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:31\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     29\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:93\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     91\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:116\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m     heappop(scheduled)\n\u001b[32m    111\u001b[39m timeout = (\n\u001b[32m    112\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    114\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    119\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\selectors.py:323\u001b[39m, in \u001b[36mSelectSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    321\u001b[39m ready = []\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     r, w, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\selectors.py:314\u001b[39m, in \u001b[36mSelectSelector._select\u001b[39m\u001b[34m(self, r, w, _, timeout)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     r, w, x = \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w + x, []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[3]: AssertionError(LLM must be set)\n",
      "Exception raised in Job[4]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[5]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[6]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[7]: AssertionError(LLM must be set)\n",
      "Exception raised in Job[8]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[9]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[10]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[11]: AssertionError(LLM must be set)\n"
     ]
    }
   ],
   "source": [
    "# ======= X·ª¨ L√ù THEO CHUNK V√Ä XOAY V√íNG API KEY =======\n",
    "for i in tqdm(range(chunk_start, num_chunks), desc=\"ƒêang ch·∫°y c√°c chunk\"):\n",
    "    chunk_df = df_testset.iloc[i * chunk_size:(i + 1) * chunk_size].reset_index(drop=True)\n",
    "    if chunk_df.empty:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # üëâ Chuy·ªÉn DataFrame chunk sang ragas_testset (theo ƒë√∫ng h√†m c·ªßa b·∫°n)\n",
    "        ragas_testset_chunk = pandas_to_ragas(chunk_df)\n",
    "\n",
    "        # üëâ Ch·ªçn API key theo round-robin\n",
    "        selected_key = list_key[i % len(list_key)]\n",
    "\n",
    "        # üëâ T·∫°o LLM wrapper t∆∞∆°ng ·ª©ng\n",
    "        llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            google_api_key=selected_key,\n",
    "            temperature=Config.Model.TEMPERATURE,\n",
    "            max_tokens=Config.Model.MAX_TOKENS,\n",
    "            timeout=None,\n",
    "            max_retries=5,\n",
    "        ))\n",
    "\n",
    "        # üëâ ƒê√°nh gi√°\n",
    "        ragas_scores_chunk = evaluate(\n",
    "            dataset=ragas_testset_chunk,\n",
    "            llm=llm,\n",
    "            embeddings=embedding_model,\n",
    "            metrics=[\n",
    "                faithfulness,\n",
    "                answer_relevancy,\n",
    "                context_precision,\n",
    "                answer_correctness\n",
    "            ],\n",
    "            run_config=run_config\n",
    "        )\n",
    "\n",
    "        # üëâ Ghi k·∫øt qu·∫£ ra file Excel\n",
    "        df_scores_chunk = ragas_scores_chunk.to_pandas()\n",
    "        # df_scores_chunk[\"chunk_index\"] = i\n",
    "        output_path = os.path.join(save_dir, f\"ragas_score_chunk_{i + 1}.xlsx\")\n",
    "        df_scores_chunk.to_excel(output_path, index=False)\n",
    "\n",
    "        print(f\"‚úÖ Chunk {i + 1} ƒë√£ x·ª≠ l√Ω xong v·ªõi API key: {selected_key}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói ·ªü chunk {i + 1} v·ªõi key {selected_key}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em m·ªõi chia tay ng∆∞·ªùi y√™u ƒë∆∞·ª£c 2 th√°ng, nh∆∞ng ...</td>\n",
       "      <td>[Question: L√†m sao ƒë·ªÉ quay tr·ªü l·∫°i? T√¥i v√† em ...</td>\n",
       "      <td>Nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u gh√™ ü•∫ Chia ...</td>\n",
       "      <td>H√£y cho ph√©p b·∫£n th√¢n ƒë∆∞·ª£c bu·ªìn. ƒê·ª´ng c·ªë g·∫Øng ...</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.842030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M√¨nh v√† ng∆∞·ªùi y√™u m√¨nh y√™u nhau ƒë∆∞·ª£c 2 nƒÉm r·ªìi...</td>\n",
       "      <td>[Question: M√¨nh v·ªõi b·ªì m√¨nh quen nhau g·∫ßn 2 nƒÉ...</td>\n",
       "      <td>T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa c·∫≠u n√®. Y√™u l√¢u m√† c·ª© ƒë·ªÅu...</td>\n",
       "      <td>L√™n k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn ƒëi ng·∫Øn ng√†y ƒë·∫øn m...</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em c·∫£m th·∫•y kh√≥ khƒÉn khi m·ªü l√≤ng v√† tin t∆∞·ªüng ...</td>\n",
       "      <td>[Question: Em mong nh·∫≠n ƒë∆∞·ª£c s·ª± t∆∞ v·∫•n c·ªßa c√°c...</td>\n",
       "      <td>T·ªõ hi·ªÉu m√†, sau nh·ªØng t·ªïn th∆∞∆°ng t·ª´ gia ƒë√¨nh t...</td>\n",
       "      <td>Th·∫•u hi·ªÉu v√† ch·∫•p nh·∫≠n qu√° kh·ª© l√† b∆∞·ªõc ƒë·∫ßu ti√™...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.891097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.273067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Em m·ªõi chia tay ng∆∞·ªùi y√™u ƒë∆∞·ª£c 2 th√°ng, nh∆∞ng ...   \n",
       "1  M√¨nh v√† ng∆∞·ªùi y√™u m√¨nh y√™u nhau ƒë∆∞·ª£c 2 nƒÉm r·ªìi...   \n",
       "2  Em c·∫£m th·∫•y kh√≥ khƒÉn khi m·ªü l√≤ng v√† tin t∆∞·ªüng ...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Question: L√†m sao ƒë·ªÉ quay tr·ªü l·∫°i? T√¥i v√† em ...   \n",
       "1  [Question: M√¨nh v·ªõi b·ªì m√¨nh quen nhau g·∫ßn 2 nƒÉ...   \n",
       "2  [Question: Em mong nh·∫≠n ƒë∆∞·ª£c s·ª± t∆∞ v·∫•n c·ªßa c√°c...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Nghe c·∫≠u n√≥i m√† t·ªõ th·∫•y th∆∞∆°ng c·∫≠u gh√™ ü•∫ Chia ...   \n",
       "1  T·ªõ hi·ªÉu c·∫£m gi√°c c·ªßa c·∫≠u n√®. Y√™u l√¢u m√† c·ª© ƒë·ªÅu...   \n",
       "2  T·ªõ hi·ªÉu m√†, sau nh·ªØng t·ªïn th∆∞∆°ng t·ª´ gia ƒë√¨nh t...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  H√£y cho ph√©p b·∫£n th√¢n ƒë∆∞·ª£c bu·ªìn. ƒê·ª´ng c·ªë g·∫Øng ...       0.04878   \n",
       "1  L√™n k·∫ø ho·∫°ch cho m·ªôt chuy·∫øn ƒëi ng·∫Øn ng√†y ƒë·∫øn m...       0.50000   \n",
       "2  Th·∫•u hi·ªÉu v√† ch·∫•p nh·∫≠n qu√° kh·ª© l√† b∆∞·ªõc ƒë·∫ßu ti√™...       1.00000   \n",
       "\n",
       "   answer_relevancy  context_precision  answer_correctness  \n",
       "0          0.842030                1.0            0.354633  \n",
       "1          0.831000                1.0            0.273304  \n",
       "2          0.891097                1.0            0.273067  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ragas_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
